[{"content":"1. 什么是正则化 （以下来源于Gpt-4o mini）\n正则化（Regularization）是一种用于防止模型过拟合（overfitting）的技术，主要应用于机器学习和统计建模中。过拟合发生在模型对训练数据的学习过于深入，以至于捕捉到数据中的噪声，而不仅仅是潜在的模式。这会导致模型在新数据上的表现不佳。\n正则化的主要思想：\n惩罚复杂模型：通过在损失函数中添加额外的惩罚项（正则项），来限制模型的复杂性。这使得模型在优化时不仅考虑预测准确性，还要考虑模型的复杂程度。 正则化的作用：\n提高泛化能力：通过降低模型复杂度，使模型在新数据上的表现更为稳定。 特征选择：L1 正则化可以直接使一些特征的权重为零，从而进行特征选择。 控制过拟合：有效地防止模型学习到训练数据中的噪声，从而提升模型的预测能力。 2. 为什么要正则化 （我的笔记）\n训练模型是一个漫长且反复的过程。在对数据集进行拟合检验时，通常会出现以下三种情况：overfitting、underfitting 和just right。分别对应拟合曲线高偏差、高方差和正合适的状态。\n在高方差（过拟合）的过程中，前人总结了三种可行的办法：（1） 清洗数据（麻烦费时）; （2） 减少模型参数和大小，渐低复杂度; （3） 增加惩罚因子，也就是正则化。\n对于回归模型和对应代价函数： $$ h_{\\theta}(x)=\\theta_{0}+\\theta_{1}x_{1}+\\theta_{2}x_{2}^{2}+\\theta_{3}x_{3}^{3}+\\theta_{4}x_{4}^{4} $$ $$ J(\\theta) = \\frac{1}{m} \\sum_{i=1}^{m} (h_{\\theta}(x^{(i)}) - y^{(i)})^2 $$ 一般来说，高次项使得模型在拟合过程中更加灵活，因此告高次项是导致方差偏大的直接原因。如果让这些高次项系数接近于零，就可以很好的改善模型过拟合的问题。\n因此，我们对代价函数$J(\\theta)$进行修改如下： $$ \\operatorname*{min}_{\\theta}J(\\theta) = \\operatorname*{min}_{\\theta}\\frac{1}{2m} \\left[\\sum_{i=1}^{m}\\left(h_{\\theta}\\left(x^{(i)}\\right)-y^{(i)}\\right)^{2}+1000\\theta_{3}^{2}+10000\\theta_{4}^{2}\\right] $$ 这里我们对方程增加了两个限制条件，分别对$\\theta_3$和$\\theta_4$进行限制，不让他们过高。\n3. 如何对模型进行正则化 晚安，酸欠少女~ 介绍三种常用方法： $L_2$正则化 $L_1$正则化 Dropout 3.1 $L_2$参数正则化（Frobenius范数） 在其他学术圈，$L_2$也被称为岭回归或者Tikhonov正则。\n方法：向目标函数添加一个正则项$\\lambda \\sum_{j=1}^{n} \\theta_j^2$ $$ J(\\theta) = \\frac{1}{m} \\sum_{i=1}^{m} (h_{\\theta}(x^{(i)}) - y^{(i)})^2 + \\lambda \\sum_{j=1}^{n} \\theta_j^2 $$ 例如，对于logistic代价（吴恩达） $$ \\mathrm{J~(w,b)=\\frac1m~\\sum_{i=1}^m~\\left(\\hat{y}^{(i)},y^{(i)}\\right)} $$ 可加入正则项，形成以下公式： $$ \\mathrm{J~(w,b)=\\frac1m~\\sum_{i=1}^m~\\left(\\hat{y}^{(i)},y^{(i)}\\right)}+\\frac{\\lambda}{2m}\\left\\|\\boldsymbol{w}\\right\\|_2^2 $$ 因为$\\left|\\boldsymbol{w}\\right|_2^2=W^TW$，所以也可以写成： $$ \\mathrm{J~(w,b)=\\frac1m~\\sum_{i=1}^m~\\left(\\hat{y}^{(i)},y^{(i)}\\right)}+\\frac{\\lambda}{2m}w^Tw $$ $\\boldsymbol{w}$是模型中的权重参数向量（不包括偏置项），例如：$\\boldsymbol{w} = [w_1, w_2, \\dots, w_n]$。正则化项会对权重参数施加惩罚，以防止某些权重过大导致模型过拟合。通过惩罚权重的大小，模型会更偏向于让所有权重尽量小。\n$\\left| \\boldsymbol{w} \\right|_2^2$ 表示权重向量的 \\(L_2\\) 范数平方。数学上，\\(L_2\\) 范数的平方就是各权重的平方和： $$ \\left\\| \\boldsymbol{w} \\right\\|_2^2 = w_1^2 + w_2^2 + \\cdots + w_n^2 $$ 这一项的作用是对权重的大小进行约束。权重越大，损失函数中的正则化项就越大，因此优化时会倾向于使权重较小。通过对权重施加这个约束，可以减少模型的复杂度，使其更加平滑，避免模型对数据细节的过度拟合。\n$\\frac{\\lambda}{2m}$是一个缩放因子，其中m是训练样本的数量。具体作用如下：\n$m$: 将正则化项的贡献除以训练样本的数量$m$，这一部分主要是为了标准化，使得正则化项的影响与样本数量成比例。这保证了无论训练样本数量多少，正则化项都能起到一致的作用。\n$\\frac{\\lambda}{2}$: 这一项的引入在对损失函数进行导数求解时可以简化计算，同时$\\lambda$决定了正则化项对整体损失函数的影响程度\n为什么$L_2$正则化会起作用：\n由于在前向传播时，我们为代价函数添加了正则项$\\Omega(\\boldsymbol{\\theta})=\\frac{1}{2m}\\left|\\boldsymbol{w}\\right|_2^2$，因此在后向传播时，我们也需要把这点考虑进去。\n$1-\\frac{\\alpha\\lambda}{m}$肯定小于1，因此这就相当于进行了“权重衰减”。\n3.2 $L_1$正则化 在线性回归中，$L_1$正则化被称为Lasso回归\n对模型参数$w$的$L_1$正则化被定义为： $$ \\Omega(\\boldsymbol{\\theta})=\\left\\|\\boldsymbol{w}\\right\\|_1=\\sum_i\\left|w_i\\right| $$ 也就是个参数绝对值之和。\nL1正则化可以使得参数稀疏化，即得到的参数是一个稀疏矩阵，可以用于特征选择\n稀疏性，说白了就是模型的很多参数是0。通常机器学习中特征数量很多，例如文本处理时，如果将一个词组（term）作为一个特征，那么特征数量会达到上万个（bigram）。在预测或分类时，那么多特征显然难以选择，但是如果代入这些特征得到的模型是一个稀疏模型，很多参数是0，表示只有少数特征对这个模型有贡献，绝大部分特征是没有贡献的，即使去掉对模型也没有什么影响，此时我们就可以只关注系数是非零值的特征。这相当于对模型进行了一次特征选择，只留下一些比较重要的特征，提高模型的泛化能力，降低过拟合的可能。 L2正则化可以防止模型过拟合（overfitting）；一定程度上，L1也可以防止过拟合。\n还是看文章吧，比较难以理解，之后再补。深入理解L1、L2正则化\n3.3 Dropout（随机失活） 黑匣子，很随机，常用于CV领域\n其主要思想就是在标准neural net中随机删去一些结点，让拟合曲线不再复杂。\n假设你在训练（a）图这样的神经网络，它存在过拟合，这就是dropout所要处理的，我们复制这个神经网络，dropout会遍历网络的每一层，并设置消除神经网络中节点的概率。假设网络中的每一层，每个节点都以抛硬币的方式设置概率，每个节点得以保留和消除的概率都是0.5，设置完节点概率，我们会消除一些节点，然后删除掉从该节点进出的连线，最后得到一个节点更少，规模更小的网络（b），然后用backprop 方法进行训练。\n实施dropout的常用方法——inverted dropout（反向随机失活）\n例如，在层数只有3的一个神经网络中，我们先生成$d^{[3]}$表示一个三层的dropout向量。\n1 d3 = np.random.rand(a3.shape[0],a3.shape[1]) \u0026lt; keep_prop 并看其每一项是否都小于某数，称之为keep_prop，这是一个具体数字。如此，便为d3以keep_prop的概率生成了True和False的矩阵。\n接下来用a3叉乘d3就可以得到最后经过dropout的a3。\n1 2 a3 = np.multipy(a3,d3) a3 /= keep_prop 最后a3需要÷keep_prop保持期望值不变。\n它的功能是，不论keep-prop 的值是多少0.8，0.9 甚至是1，如果keep-prop 设置为1，那么就不存在dropout，因为它会保留所有节点。反向随机失活（inverted dropout）方法通过除以keep-prob，确保$𝑎^{[3]}$的期望值不变。\n为什么drop-out会起作用？\n直观上理解：不要依赖于任何一个特征，因为该单元的输入可能随时被清除，因此该单元通过这种方式传播下去，并为单元的四个输入增加一点权重，通过传播所有权重，dropout 将产生收缩权重的平方范数的效果，和之前讲的𝐿2正则化类似；实施dropout 的结果实它会压缩权重，并完成一些预防过拟合的外层正则化；𝐿2对不同权重的衰减是不同的，它取决于激活函数倍增的大小。 第二个直观认识是，我们从单个神经元入手。通过dropout，特殊单元的输入几乎被消除，有时这两个单元会被删除，有时会删除其它单元，就是说，一个特殊单元，它不能依靠任何特征，因为特征都有可能被随机清除，或者说该单元的输入也都可能被随机清除。我不愿意把所有赌注都放在一个节上，不愿意给任何一个输入加上太多权重，因为它可能会被删除，因此该单元将通过这种方式积极地传播开，并为单元的四个输入增加一点权重，通过传播所有权重，dropout 将产生收缩权重的平方范数的效果，和我们之前讲过的𝐿2正则化类似，实施dropout 的结果是它会压缩权重，并完成一些预防过拟合的外层正则化。 实施dropout 的另一个细节是，这是一个拥有三个输入特征的网络，其中一个要选择的参数是keep-prob，它代表每一层上保留单元的概率。所以不同层的keep-prob 也可以变化。第一层，矩阵𝑊[1]是7×3，第二个权重矩阵𝑊[2]是7×7，第三个权重矩阵𝑊[3]是3×7，以此类推，𝑊[2]是最大的权重矩阵，因为𝑊[2]拥有最大参数集，即7×7，为了预防矩阵的过拟合，对于这一层，我认为这是第二层，它的keep-prob 值应该相对较低，假设是0.5。对于其它层，过拟合的程度可能没那么严重，它们的keep-prob 值可能高一些，可能是0.7，这里是0.7。如果在某一层，我们不必担心其过拟合的问题，那么keep-prob 可以为1。 dropout的缺点。\ndropout 一大缺点就是代价函数𝐽不再被明确定义，每次迭代，都会随机移除一些节点，如果再三检查梯度下降的性能，实际上是很难进行复查的。定义明确的代价函数𝐽每次迭代后都会下降，因为我们所优化的代价函数J 实际上并没有明确定义，或者说在某种程度上很难计算，所以我们失去了调试工具来绘制这样的图片。我通常会关闭dropout 函数，将keep-prob 的值设为1，运行代码，确保𝐽函数单调递减。然后打开dropout 函数，希望在dropout 过程中，代码并未引入bug。 4. Conclusion 总结，解决训练模型过拟合问题最常用的办法就是正则化，正则化常用的有三种方法：$L_2$正则化；$L_1$正则化；和$Dropout$。\n其中$L_2$正则化和$Dropout$的本质原理都是一样的，$L_1$正则化也有一定防止过拟合的功能，但更多用于参数稀疏化。\n“谁都不可能和谁在一起一辈子，人就是这样，必须去习惯失去。” ——《秒速五厘米》 ","date":"2024-10-02T23:02:07+08:00","image":"https://cdn.jsdelivr.net/gh/Sazerac-kk/pictures/img/202410032049240.png","permalink":"https://Sazerac-kk.github.io/p/deep-learning-what-is-regularisation/","title":"Deep Learning: What is regularisation ?"},{"content":"1. 登录AutoDL算力云 当然也有免费的平台\nkaggle：\n不需要科学上网，但是文件加载有些麻烦，我第一次尝试失败（应该是我的问题），每个月有30个小时的GPU时长。\ncolab：需要科学上网，响应比较慢，但是传文件挺快的，没有conda，而且不知道为什么python版本限制在3.7改也改不回来。\nAutoDL网址：https://www.autodl.com/\n可以登录我的账号。 可以开发票（最爽！）。 更接近于原生ubuntu，有jupyter和script等选择。 显卡比较贵，而且晚上未必有。 支持vscode远程连接！！！！ 2. 加载+配置环境【最痛苦的一集】 首先，选择空闲卡，配置基础环境。\n先用最接近的，创建好之后还可以改。\n进入控制台 - \u0026gt; 容器实例，查看SSH登录（也可直接在平台登陆）。\n打开vscode，进入远程资源管理器，点击“+”，新建远程，填入登陆指令和密码。\n进入后打开终端，会出现以下提示，说明连接成功。\n创建文件夹Working，按照指令，先建立conda环境\n1 2 conda create -n regionclip python=3.9 # 创建环境 source activate regionclip # 进入环境 下载pytorch和cuda，作者给的指令貌似有些问题。\n1 pip install torch==1.10.1+cu111 torchvision==0.11.2+cu111 torchaudio==0.10.1 -f https://download.pytorch.org/whl/cu111/torch_stable.html 这条指令没什么问题。\n将代码下载。\n1 2 3 git clone git@github.com:microsoft/RegionCLIP.git # 或者 git clone https://github.com/microsoft/RegionCLIP.git 配置基本环境。（这里bug非常多）\n1 python -m pip install -e RegionCLIP 运行这一条发现会出现这种情况：\n很多教程里面都没有提到这个内容，其实这是由于setuptools版本不兼容导致，应当运行以下代码：\n1 pip install setuptools==59 setup issue · Issue #60 · microsoft/RegionCLIP (github.com)\n但是这并不能完全解决问题，例如我仍然运行配置环境的代码，会出现以下错误：\n1 2 3 4 5 6 7 Obtaining file:///mnt/d/ZYY/RegionCLIP Preparing metadata (setup.py) ... done ERROR: Exception: ······ File \u0026#34;/home/frain/micromamba/envs/region/lib/python3.9/site-packages/pip/_vendor/packaging/version.py\u0026#34;, line 202, in init raise InvalidVersion(f\u0026#34;Invalid version: \u0026#39;{version}\u0026#39;\u0026#34;) pip._vendor.packaging.version.InvalidVersion: Invalid version: \u0026#39;RegionCLIP\u0026#39; 这需要我们对setup.py文件进行配置，将 version=get_version() 改成 version='0.1.0' 。 然后就可以运行了。 然后配置额外的环境\n1 2 pip install opencv-python timm diffdist h5py scikit-learn ftfy pip install git+https://github.com/lvis-dataset/lvis-api.git 应该会比较顺利\n3. 下载预训练数据和数据集 这里面没什么好说的，按照教程下载即可，但注意预训练数据只需要按需下载，在以下的教程中，只需要下载pretrained_ckpt/concept_emb/lvis_1203_cls_emb_rn50x4.pth和pretrained_ckpt/regionclip/regionclip_pretrained-cc_rn50x4.pth文件（文件路径需要存在）。\n​\tregionclip 服务器复现 - 知乎 (zhihu.com)\n4. 测试运行 以下代码：\n1 2 3 4 5 6 7 8 9 10 python3 ./tools/train_net.py \\ --eval-only \\ --num-gpus 1 \\ --config-file ./configs/LVISv1-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_custom_img.yaml \\ MODEL.WEIGHTS ./pretrained_ckpt/regionclip/regionclip_pretrained-cc_rn50x4.pth \\ MODEL.CLIP.TEXT_EMB_PATH ./pretrained_ckpt/concept_emb/lvis_1203_cls_emb_rn50x4.pth \\ MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/LVISv1-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml \\ MODEL.CLIP.TEXT_EMB_DIM 640 \\ MODEL.RESNETS.DEPTH 200 \\ MODEL.ROI_BOX_HEAD.POOLER_RESOLUTION 18\\ 可视化：\n1 2 3 4 5 6 7 8 python ./tools/visualize_json_results.py \\ --input ./output/inference/lvis_instances_results.json \\ --output ./output/regions \\ --dataset lvis_v1_val_custom_img \\ --conf-threshold 0.05 \\ --show-unique-boxes \\ --max-boxes 25 \\ --small-region-px 8100\\ 终端运行即可。\n可能会遇到的问题：\n1 _C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZN2at19UndefinedTensorImpl10_singletonE 这个好像是pytorch重复编译的问题，解决办法：\n1 remove -r build # 在RegionCLIP文件夹下 1 pip install -v -e # 在有setup.py的文件夹下 等待时间比较长，运行结束问题解决！\n5. My_RegionCLIP 我在原microsoft的RegionCLIP文件上进行了环境配置，生成了requirements.txt文件，可以一键配置环境。\n1 conda install --yes --file requirements.txt 另外，测试脚本也写好，在./run文件夹下面，可直接用sh run/run1.sh和sh run/run2.sh来运行。但是数据集和预训练数据过大，就没有再GitHub上传。\n仓库地址：https://github.com/Sazerac-kk/My_RegionCLIP.git\n","date":"2024-09-24T23:02:07+08:00","permalink":"https://Sazerac-kk.github.io/p/regionclip%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/","title":"RegionCLIP踩坑记录"},{"content":"环境准备 下载Hugo 官网址：Hugo官网\nGithub地址:gohugoio/hugo\n点击Github，点击Tags，选择合适的版本下载。\n下载git 点击Git官网https://cdn.jsdelivr.net/gh/Sazerac-kk/pictures/img/image1.png\n点击 Download for Windows 按照指引安装即可。\n搭建博客 创建Blog 解压hugo_extended_0.134.2_windows-amd64.zip文件，点击进入并cmd打开命令行窗口，输入hugo new site xxxx创建文件（我这里是dev）。\n但是新创建的dev文件夹里面没有hugo.exe文件，为了使在dev文件下仍能使用hugo命令，需要复制hugo.exe文件到dev文件内。\n在命令行中切换到已创建好的dev文件夹，输入hugo server -D，运行成功出现以下界面：\n打开浏览器输入http://localhost:1313/发现会出现以下界面：\n这是因为还未下载主题，可以看到dev\\themes文件夹下为空。\n下载主题 再次进入Hugo官网。\n点击Themes选择一款适合的主题，作为演示，我选择的是Stack这款主题。\n点击Download进入主题github界面，并选择适当的版本下载。\n将文件解压存储在dev\\themes文件下，并将exampleSite样例数据中的 Content 和 hugo.yaml 复制到主文件夹中，并删掉hugo.toml。\n修改themes文件夹下面主题文件夹的名字，使其和hugo.yaml中的一样。\n再次在命令行中输入hugo server -D，查看主题，发现已经正确显示。\nGithub部署 常规部署 准备工作：创建一个自己的github账号。\n新建仓库，命名要用{github用户名}.github.io，如果这是你搭建的第一个博客，这一步最好在前面用自己的用户名，这会避免很多Bug（也许是我太菜了~）。\n然后进入自己的仓库，前往setting -\u0026gt; Pages -\u0026gt; Branch选择main分支，然后保存，会自动开启https://{github用户名}.github.io 的地址，这地址也是以后访问博客的地址。（注意：仓库需要设置为public）\n然后我们就可以往github仓库上传文件了，先回到dev文件下，进入命令行界面，输入hugo -D生成public文件夹。\n在public文件夹下执行以下命令上传到github仓库上面。\n1 2 3 4 5 6 git init git add . git commit -m \u0026#34;first commit\u0026#34; git branch -M main git remote add origin {你的github仓库地址} git push -u origin main 上传成功后访https://{github用户名}.github.io，成功搭建属于自己的Hugo博客。\nGithub Action自动部署 Github上面重新建一个仓库，用于存放Hugo的主文件，可以设置为private。\n前往settings -\u0026gt; Developer Settings -\u0026gt; Personal access tokens，创建一个token(classic)。\ntoken选择永不过期，并且勾选repo和workflow选项。\n为保证安全，将生成的token，保存的仓库的变量中，前往Settings -\u0026gt; Secrets and variables -\u0026gt; Actions中设置。（注意：token只能显示一次，可事先保存）\n在hugo主文件创建一个.github/workflows/xxxx.yaml文件，将以下内容复制进去，想具体了解更多，可查看【Github Action文档】。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 name: deploy # 代码提交到main分支时触发github action on: push: branches: - main jobs: deploy: runs-on: ubuntu-latest steps: - name: Checkout uses: actions/checkout@v4 with: fetch-depth: 0 - name: Setup Hugo uses: peaceiris/actions-hugo@v3 with: hugo-version: \u0026#34;latest\u0026#34; extended: true - name: Build Web run: hugo -D - name: Deploy Web uses: peaceiris/actions-gh-pages@v4 with: PERSONAL_TOKEN: ${{ secrets.你的token变量名 }} EXTERNAL_REPOSITORY: 你的github名/你的仓库名 PUBLISH_BRANCH: main PUBLISH_DIR: ./public commit_message: auto deploy 在hugo主文件创建.gitignore文件，来避免提交不必要的文件。\n1 2 3 4 5 6 7 # 自动生成的文件 public resources .hugo_build.lock # hugo命令 hugo.exe 将hugo的主文件上传到仓库，上传成功后会触发Github Action，来自动部署你的静态页面。\n1 2 3 4 5 6 git init git add . git commit -m \u0026#34;first commit\u0026#34; git branch -M main git remote add origin {你的github仓库地址} git push -u origin main 参考资料 “【Hugo】Hugo + Github 免费部署自己的博客.” 莱特雷-letere, 30 Aug. 2024 【Hugo】Hugo + Github 免费部署自己的博客 (letere-gzj.github.io)\n原文视频\n","date":"2024-09-17T21:26:39+08:00","image":"https://cdn.jsdelivr.net/gh/Sazerac-kk/pictures/img/202409181730842.png","permalink":"https://Sazerac-kk.github.io/p/%E6%95%99%E7%A8%8Bhugo-github%E5%8D%9A%E5%AE%A2%E9%83%A8%E7%BD%B2/","title":"【教程】Hugo+Github博客部署"},{"content":"快速扫盲 深度学习(deeplearning)包含很多向量或矩阵的运算，因此对线性代数有足够的了解是非常必要的\n其中最主要的知识点包括：\n标量、向量、矩阵和张量，以及矩阵的转置运算\n矩阵和向量乘法\n矩阵乘法 (叉乘) $$ C_{i, j}=\\sum_{k} A_{i, k} B_{k, j} $$ Hadamard乘积 指两个矩阵中对应元素的乘积 单位矩阵和逆矩阵\n线性相关和线性无关\n生成子空间\n范数\n正交矩阵和标准正交\n特征分解（平衡分布） $$ A = QAQ^T $$ 奇异值分解\nMoore- Penrose伪逆\n迹运算\n行列式\n教材资源：线性代数与解析几何\n提取码：5sz2\n","date":"2024-09-17T21:00:13+08:00","image":"https://Sazerac-kk.github.io/p/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/mansuiyanhua_hu17338915106485599663.jpg","permalink":"https://Sazerac-kk.github.io/p/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/","title":"深度学习预备知识：线性代数"},{"content":"matplotlib.pyplot是 matplotlib 的基于状态的接口。它提供了一种隐式的、类似 MATLAB 的绘图方式。它还会在屏幕上打开图形，并充当图形 GUI 管理器。\n1、显示窗口和隐式窗口 1）pyplot 主要用于交互式绘图和程序化绘图生成的简单情况，而对于复杂绘图，建议使用显示的面向对象的API，此时pyplot用于创建图形有一集图形中的轴。\n2）请参阅pyplot.figure、pyplot.subplots、 和 pyplot.subplot_mosaic创建图形，以及 轴 API以了解轴上的绘图方法。有关隐式接口和显式接口之间权衡的说明，请参阅Matplotlib 应用程序接口 (API) 。\n2、管理图像和轴 1)axes:将Axes添加到当前图形并使其成为当前Axes。 Call signatures:\nParameters:\narg : None or 4-tuple\n​None:一个用subplot(**kwargs)生成的新的窗口Axes\n​4-tuple : rect = (left, bottom, width, height)，以此为标准创建了一个新的轴。\nProjection:{None, \u0026lsquo;aitoff\u0026rsquo;, \u0026lsquo;hammer\u0026rsquo;, \u0026rsquo;lambert\u0026rsquo;, \u0026lsquo;mollweide\u0026rsquo;, \u0026lsquo;polar\u0026rsquo;, \u0026lsquo;rectilinear\u0026rsquo;, str}\n可选的投影类型，None代表直线\n详情见：projections\nmatplotlib.projections.get_projection_names()返回当前注册的所有投影的名称\nPolar: bool, default ,:False # 极性\n如果为True 代表投影=‘极坐标’ Sharex, sharey: Axes ,可选：\naxis与 sharex 和/或 sharey共享 x 或 y 。该轴将具有与共享轴相同的限制、刻度和比例。 Label: str\nAxes返回的标签 Return：\nAxes或者子类Axes：\n返回的类型取决于projection，直线：Axes; 极坐标：projections.polar.PolarAxes\n其他参数：\nkwargs：详情请见axes 2）其他: axes 将 Axes 添加到当前图形并使其成为当前 Axes。 cla 清除当前轴。 clf 清除当前数字。 close 关闭图形窗口。 delaxes Axes从图中删除一个（默认为当前轴）。 fignum_exists 返回给定 id 的图窗是否存在。 figure 创建新图窗，或激活现有图窗。 gca 获取当前的轴。 gcf 获取当前数字。 get_figlabels 返回现有图形标签的列表。 get_fignums 返回现有图号的列表。 sca 将当前 Axes 设置为ax并将当前Figure 设置为ax的父级。 subplot 将轴添加到当前图形或检索现有轴。 subplot2grid 在常规网格内的特定位置创建子图。 subplot_mosaic 基于 ASCII 艺术或嵌套列表构建轴布局。 subplots 创建一个图形和一组子图。 twinx 制作并返回共享x轴的第二个轴。 twiny 创建并返回共享y轴的第二个轴。 3、将数据添加到图中 基本：\nplot 将 y 与 x 绘制为线条和/或标记。 errorbar 将 y 与 x 绘制为带有误差条的线条和/或标记。 scatter y与y的散点图 plot_date [不鼓励] 绘制强制轴将浮点数视为日期的图。 step 制作一个步骤图。 loglog 在 x 轴和 y 轴上绘制对数缩放图。 semilogx 在 x 轴上绘制对数缩放图。 semilogy 在 y 轴上绘制对数缩放图。 fill_between 填充两条水平曲线之间的区域。 fill_betweenx 填充两条垂直曲线之间的区域。 bar 绘制条形图。 barh 绘制水平条形图。 bar_label 标记条形图。 stem 创建一个茎图。 eventplot 在给定位置绘制相同的平行线。 pie 绘制饼图。 stackplot 绘制堆积面积图。 broken_barh 绘制矩形的水平序列。 vlines 在每个x 处绘制从ymin到ymax 的垂直线。 hlines 在每个y 处绘制从xmin到xmax 的水平线。 fill 绘制填充多边形。 polar 绘制极坐标图。 二维数组：\nimshow 将数据显示为图像，即在二维规则光栅上。 matshow 在新的图窗窗口中将数组显示为矩阵。 pcolor 使用不规则矩形网格创建伪彩色图。 pcolormesh 使用不规则矩形网格创建伪彩色图。 spy 绘制二维数组的稀疏模式。 figimage 将未重新采样的图像添加到图中。 文本和注释：\nannotate 用文本text注释点xy。 text 将文本添加到轴。 figtext 向图中添加文本。 table 将表添加到Axes. arrow 向轴添加箭头。 figlegend 在图上放置图例。 legend 在轴上放置一个图例。 4、轴配置： autoscale 根据数据自动缩放轴视图（切换）。 axis 获取或设置某些轴属性的便捷方法。 box 打开或关闭当前轴上的轴框。 grid 配置网格线。 locator_params 主要蜱虫定位器的控制行为。 minorticks_off 删除轴上的小刻度。 minorticks_on 在轴上显示小刻度。 rgrids 获取或设置当前极坐标图上的径向网格线。 thetagrids 获取或设置当前极坐标图上的 theta 网格线。 tick_params 更改刻度、刻度标签和网格线的外观。 ticklabel_format 配置ScalarFormatter线性轴的默认使用。 xlabel 设置 x 轴的标签。 xlim 获取或设置当前轴的 x 限制。 xscale 设置 x 轴的比例。 xticks 获取或设置 x 轴的当前刻度位置和标签。 ylabel 设置 y 轴的标签。 ylim 获取或设置当前轴的 y 限制。 yscale 设置 y 轴的比例。 yticks 获取或设置 y 轴的当前刻度位置和标签。 suptitle 向图中添加居中的副标题。 title 为轴设置标题。 5、布局： margins 设置或检索自动缩放边距。 subplots_adjust 调整子图布局参数。 subplot_tool 启动图形的子图工具窗口。 tight_layout 调整子图之间和子图周围的填充。 6、颜色映射： clim 设置当前图像的颜色限制。 colorbar 将颜色条添加到绘图中。 gci 获取当前的可着色艺术家。 sci 设置当前图像。 get_cmap 获取一个颜色图实例，如果name为 None，则默认为 rc 值。 set_cmap 设置默认颜色图，并将其应用到当前图像（如果有）。 imread 将图像从文件读取到数组中。 imsave 颜色映射并将数组保存为图像文件。 7、输出： draw 重新绘制当前图形。 draw_if_interactive 如果处于交互模式，则重绘当前图形。 ioff 禁用交互模式。 ion 启用交互模式。 install_repl_displayhook 连接到当前shell的显示钩子。 isinteractive 返回每个绘图命令后是否更新绘图。 pause 将 GUI 事件循环运行间隔秒。 savefig 保存当前图形。 show 显示所有开放数字。 switch_backend 设置 pyplot 后端。 uninstall_repl_displayhook 与当前 shell 的显示挂钩断开连接。 8、其他详见： https://matplotlib.org/stable/api/pyplot_summary.html\n","date":"2024-09-17T00:00:00Z","image":"https://Sazerac-kk.github.io/p/the-use-of-matplotlib/image_hu13700394000997497419.png","permalink":"https://Sazerac-kk.github.io/p/the-use-of-matplotlib/","title":"The use of matplotlib"},{"content":"Mathematical notation in a Hugo project can be enabled by using third party JavaScript libraries.\nIn this example we will be using KaTeX\nCreate a partial under /layouts/partials/math.html Within this partial reference the Auto-render Extension or host these scripts locally. Include the partial in your templates like so: 1 2 3 {{ if or .Params.math .Site.Params.math }} {{ partial \u0026#34;math.html\u0026#34; . }} {{ end }} To enable KaTeX globally set the parameter math to true in a project\u0026rsquo;s configuration To enable KaTeX on a per page basis include the parameter math: true in content files Note: Use the online reference of Supported TeX Functions\nExamples Inline math: $\\varphi = \\dfrac{1+\\sqrt5}{2}= 1.6180339887…$\nBlock math: $$ \\varphi = 1+\\frac{1} {1+\\frac{1} {1+\\frac{1} {1+\\cdots} } } $$","date":"2019-03-08T00:00:00Z","permalink":"https://Sazerac-kk.github.io/p/math-typesetting/","title":"Math Typesetting"}]